{
  "title": "MongoDB Tips & Tricks",
  "publishedAt": "2022-05-21",
  "summary": "What I Learned From Refactoring Sevenwiki.",
  "body": {
    "raw": "\n# MongoDB apparently can't handle Humongous data due to its design.\n\nMongoDB. We all know, we all praise. NoSQL! How wonderful is it?\n\nBut, when you start to dive deep in into the complexities of it,\nit sort of feels like... lost.\n\nWe, or at least I thought it was such a wonderful database,\nfast, scalable, and developer-friendly. (Well, you might think it still is.)\nBut it wasn't all sunshines and rainbows :/\nI had quite a lot of nit-picky skills to learn by trial-and-error.\n\nSo this post is about the common pitfalls you would want to avoid while using MongoDB.\n\nFirst, we'll talk about something a bit more shallow: arrays.\n\n# Arrays\n\n> A backend developer crying out while he first meets MongoDB:\n> **Hooray! No more crappy tables and relations and joins and all that s\\*\\*\\*!**\n\n> The day after service launch:\n> `mongodb: maximum file size exceeded.`\n\nWith MongoDB, people started throwing out a bunch of array-focused models.\nWell, It's easier for the devs to code!\n\nBut MongoDB uses BSON.\nBSON can only store 16MB.\nIf it exceeds 16MB, which quite commonly occurs for history files,\nlog files, and the like, it spits out an error.\n\nWhat happens next?\n\nUser input gets ignored, services malfunction,\nservers crash (when even errors aren't properly handled), and BOOM!\n\nSo how can we fix this....\n\n## The easier way (with caveats)\n\nThe lazy developer might say, why don't we just extend the maximum limit from,\nsay, 16MB to 64MB?\n\nAnd, it would **work**, thanks to the MongoDB devs who created GridFS.\n\nHappily ever after.\n\n## The harder way (that pays you back)\n\nA more sophisticated developer would try to refactor the models.\n\nShe would separate arrays, make an array element into a separate model,\nthose models would reference back the original document,\nby something like `'parent_id': 'some_random_ObjectId'`.\n\nThat would allow the developer to query elements of that new model\nand retrieve only elements that have the `parent_id` to something.\n\nThis achieves the same functionality with, well, not exceeding the limit.\n\nSince each element is stored in a separate document, it should still have plenty of capacity left.\n\nThe drawback of this approach is, I guess, a subtle increase in time complexity (or MongoDB might optimize the call and make it even faster)?\n\n# To Be Continued...\n",
    "html": "<h1>MongoDB apparently can't handle Humongous data due to its design.</h1>\n<p>MongoDB. We all know, we all praise. NoSQL! How wonderful is it?</p>\n<p>But, when you start to dive deep in into the complexities of it,\nit sort of feels like... lost.</p>\n<p>We, or at least I thought it was such a wonderful database,\nfast, scalable, and developer-friendly. (Well, you might think it still is.)\nBut it wasn't all sunshines and rainbows :/\nI had quite a lot of nit-picky skills to learn by trial-and-error.</p>\n<p>So this post is about the common pitfalls you would want to avoid while using MongoDB.</p>\n<p>First, we'll talk about something a bit more shallow: arrays.</p>\n<h1>Arrays</h1>\n<blockquote>\n<p>A backend developer crying out while he first meets MongoDB:\n<strong>Hooray! No more crappy tables and relations and joins and all that s***!</strong></p>\n</blockquote>\n<blockquote>\n<p>The day after service launch:\n<code>mongodb: maximum file size exceeded.</code></p>\n</blockquote>\n<p>With MongoDB, people started throwing out a bunch of array-focused models.\nWell, It's easier for the devs to code!</p>\n<p>But MongoDB uses BSON.\nBSON can only store 16MB.\nIf it exceeds 16MB, which quite commonly occurs for history files,\nlog files, and the like, it spits out an error.</p>\n<p>What happens next?</p>\n<p>User input gets ignored, services malfunction,\nservers crash (when even errors aren't properly handled), and BOOM!</p>\n<p>So how can we fix this....</p>\n<h2>The easier way (with caveats)</h2>\n<p>The lazy developer might say, why don't we just extend the maximum limit from,\nsay, 16MB to 64MB?</p>\n<p>And, it would <strong>work</strong>, thanks to the MongoDB devs who created GridFS.</p>\n<p>Happily ever after.</p>\n<h2>The harder way (that pays you back)</h2>\n<p>A more sophisticated developer would try to refactor the models.</p>\n<p>She would separate arrays, make an array element into a separate model,\nthose models would reference back the original document,\nby something like <code>'parent_id': 'some_random_ObjectId'</code>.</p>\n<p>That would allow the developer to query elements of that new model\nand retrieve only elements that have the <code>parent_id</code> to something.</p>\n<p>This achieves the same functionality with, well, not exceeding the limit.</p>\n<p>Since each element is stored in a separate document, it should still have plenty of capacity left.</p>\n<p>The drawback of this approach is, I guess, a subtle increase in time complexity (or MongoDB might optimize the call and make it even faster)?</p>\n<h1>To Be Continued...</h1>"
  },
  "_id": "blog/mongodb-tips-and-tricks.mdx",
  "_raw": {
    "sourceFilePath": "blog/mongodb-tips-and-tricks.mdx",
    "sourceFileName": "mongodb-tips-and-tricks.mdx",
    "sourceFileDir": "blog",
    "contentType": "mdx",
    "flattenedPath": "blog/mongodb-tips-and-tricks"
  },
  "type": "Blog",
  "readingTime": {
    "text": "2 min read",
    "minutes": 1.4,
    "time": 84000,
    "words": 385
  },
  "wordCount": 387,
  "tweetIds": [],
  "slug": "mongodb-tips-and-tricks"
}